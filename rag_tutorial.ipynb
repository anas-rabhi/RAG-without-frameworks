{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "The only libraries that are going to be used are : \n",
    "- OpenAI : To call the LLM & Embedding model\n",
    "- PyPDF2 : To process the text inside each PDF\n",
    "- ChromaDB : To create a VectorDB and save the documents/chunks and their embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from PyPDF2 import PdfReader\n",
    "import openai\n",
    "\n",
    "# Set up OpenAI API (make sure to set your API key as an environment variable)\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Chroma Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chroma client : Persistent client to save this DB into the Disk. \n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "# Create a collection \n",
    "collection = chroma_client.create_collection(\"pdf_collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "The idea here is :\n",
    "- Retrieve all the text from PDFs\n",
    "- Divide them into chunks\n",
    "- Get for each chunk a vector representation (embeddings)\n",
    "- Store each chunk inside the ChromaDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract all the text from a PDF file.\n",
    "    \"\"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PdfReader(file)\n",
    "        text = \"\"\n",
    "        # Iterate through all pages and extract text\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def split_text_into_chunks(text, words_per_chunk=500, overlap=50):\n",
    "    \"\"\"\n",
    "    Split text into smaller chunks for better embedding.\n",
    "    \"\"\"\n",
    "    # Split text into words\n",
    "    words = re.findall(r'\\S+', text)\n",
    "    chunks = []\n",
    "    # Create overlapping chunks\n",
    "    for i in range(0, len(words), words_per_chunk - overlap):\n",
    "        chunk = ' '.join(words[i:i + words_per_chunk])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"\n",
    "    Call OpenAI API to create embeddings for a given text.\n",
    "    \"\"\"\n",
    "    # Call OpenAI API to generate embedding\n",
    "    response = openai.Embedding.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "\n",
    "def process_pdfs(folder_path):\n",
    "    \"\"\"\n",
    "    Process the PDFs: \n",
    "    1. Extract the text\n",
    "    2. Convert the text into chunks\n",
    "    3. Get embeddings for each chunk\n",
    "    4. Load the chunks and the embeddings inside the chroma DB\n",
    "    \n",
    "    PS : We can also request OpenAI with batches...\n",
    "    \"\"\"\n",
    "\n",
    "    doc_id = 0\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Extract text from PDF\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            \n",
    "            # Split text into chunks\n",
    "            chunks = split_text_into_chunks(text)\n",
    "            \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                # Create embeddings using OpenAI\n",
    "                embedding = get_embedding(chunk)\n",
    "                \n",
    "                # Add to Chroma: Some of the VectorDB allow inserting batches\n",
    "                collection.add(\n",
    "                    embeddings=[embedding],\n",
    "                    documents=[chunk],\n",
    "                    metadatas=[{\"source\": filename, \"chunk\": i}],\n",
    "                    ids=[f\"{filename}_chunk_{i}\"]\n",
    "                )\n",
    "                doc_id += 1\n",
    "\n",
    "    print(f\"Processed and added {len(collection.get()['ids'])} chunks to Chroma.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"./data\"  # Replace it with your PDF folder path\n",
    "process_pdfs(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble everything\n",
    "\n",
    "The process, once the ChromaDB is populated, for each user question:\n",
    "- Generate the embedding of the question\n",
    "- Query ChromaDB with the question embedding to retrieve the most relevant chunks\n",
    "- Send the retrieved chunks and the original question to the LLM to formulate an answer based on the provided context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_chroma(query_embedding, n_results=5):\n",
    "    \"\"\"\n",
    "    Query ChromaDB for relevant documents using the query embedding.\n",
    "    \"\"\"\n",
    "    # Query ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    # Return the first list of documents\n",
    "    return results['documents'][0]\n",
    "\n",
    "def generate_answer(question, context):\n",
    "    \"\"\"\n",
    "    Generate an answer using OpenAI's API with the given context.\n",
    "    \"\"\"\n",
    "    # Call OpenAI API\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"You are a helpful assistant. Use the following context to answer the user's question: {context}\\n\\n --------\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "    )\n",
    "    # Extract and return the generated answer\n",
    "    return response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(question):\n",
    "    \"\"\"\n",
    "    Executes the RAG pipeline.\n",
    "    \"\"\"\n",
    "    # Generate embedding for the question\n",
    "    question_embeddings = get_embedding(question)\n",
    "\n",
    "    # Retrieve relevant chunks from ChromaDB\n",
    "    relevant_chunks = query_chroma(question_embeddings)\n",
    "\n",
    "    # Combine chunks into a single context string\n",
    "    context = \"\\n\\n\".join(relevant_chunks)\n",
    "\n",
    "    # Generate answer using the question and context\n",
    "    answer = generate_answer(question, context)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How to get a composteur gratuit *english accent*\n",
    "rag_pipeline(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.query(vector)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
